{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANALYSIS WITH MACHINE LEARNING ALGORITHMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ï»¿country</th>\n",
       "      <th>year</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>suicides_no</th>\n",
       "      <th>population</th>\n",
       "      <th>suicides/100k pop</th>\n",
       "      <th>country-year</th>\n",
       "      <th>HDI for year</th>\n",
       "      <th>gdp_for_year ($)</th>\n",
       "      <th>gdp_per_capita ($)</th>\n",
       "      <th>generation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Albania</td>\n",
       "      <td>1987</td>\n",
       "      <td>male</td>\n",
       "      <td>15-24 years</td>\n",
       "      <td>21</td>\n",
       "      <td>312900</td>\n",
       "      <td>6.71</td>\n",
       "      <td>Albania1987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2,156,624,900</td>\n",
       "      <td>796</td>\n",
       "      <td>Generation X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>1987</td>\n",
       "      <td>male</td>\n",
       "      <td>35-54 years</td>\n",
       "      <td>16</td>\n",
       "      <td>308000</td>\n",
       "      <td>5.19</td>\n",
       "      <td>Albania1987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2,156,624,900</td>\n",
       "      <td>796</td>\n",
       "      <td>Silent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Albania</td>\n",
       "      <td>1987</td>\n",
       "      <td>female</td>\n",
       "      <td>15-24 years</td>\n",
       "      <td>14</td>\n",
       "      <td>289700</td>\n",
       "      <td>4.83</td>\n",
       "      <td>Albania1987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2,156,624,900</td>\n",
       "      <td>796</td>\n",
       "      <td>Generation X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Albania</td>\n",
       "      <td>1987</td>\n",
       "      <td>male</td>\n",
       "      <td>75+ years</td>\n",
       "      <td>1</td>\n",
       "      <td>21800</td>\n",
       "      <td>4.59</td>\n",
       "      <td>Albania1987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2,156,624,900</td>\n",
       "      <td>796</td>\n",
       "      <td>G.I. Generation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Albania</td>\n",
       "      <td>1987</td>\n",
       "      <td>male</td>\n",
       "      <td>25-34 years</td>\n",
       "      <td>9</td>\n",
       "      <td>274300</td>\n",
       "      <td>3.28</td>\n",
       "      <td>Albania1987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2,156,624,900</td>\n",
       "      <td>796</td>\n",
       "      <td>Boomers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ï»¿country  year     sex          age  suicides_no  population  \\\n",
       "0    Albania  1987    male  15-24 years           21      312900   \n",
       "1    Albania  1987    male  35-54 years           16      308000   \n",
       "2    Albania  1987  female  15-24 years           14      289700   \n",
       "3    Albania  1987    male    75+ years            1       21800   \n",
       "4    Albania  1987    male  25-34 years            9      274300   \n",
       "\n",
       "   suicides/100k pop country-year  HDI for year  gdp_for_year ($)   \\\n",
       "0               6.71  Albania1987           NaN      2,156,624,900   \n",
       "1               5.19  Albania1987           NaN      2,156,624,900   \n",
       "2               4.83  Albania1987           NaN      2,156,624,900   \n",
       "3               4.59  Albania1987           NaN      2,156,624,900   \n",
       "4               3.28  Albania1987           NaN      2,156,624,900   \n",
       "\n",
       "   gdp_per_capita ($)       generation  \n",
       "0                 796     Generation X  \n",
       "1                 796           Silent  \n",
       "2                 796     Generation X  \n",
       "3                 796  G.I. Generation  \n",
       "4                 796          Boomers  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "start = time. time()\n",
    "import pandas as pd\n",
    "df=pd.read_csv(\"master.csv\", engine='python')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median of column HDI for year 0.779\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ï»¿country</th>\n",
       "      <th>year</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>suicides_no</th>\n",
       "      <th>population</th>\n",
       "      <th>suicides/100k pop</th>\n",
       "      <th>country-year</th>\n",
       "      <th>HDI for year</th>\n",
       "      <th>gdp_for_year ($)</th>\n",
       "      <th>gdp_per_capita ($)</th>\n",
       "      <th>generation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Albania</td>\n",
       "      <td>1987</td>\n",
       "      <td>male</td>\n",
       "      <td>15-24 years</td>\n",
       "      <td>21</td>\n",
       "      <td>312900</td>\n",
       "      <td>6.71</td>\n",
       "      <td>Albania1987</td>\n",
       "      <td>0.779</td>\n",
       "      <td>2,156,624,900</td>\n",
       "      <td>796</td>\n",
       "      <td>Generation X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>1987</td>\n",
       "      <td>male</td>\n",
       "      <td>35-54 years</td>\n",
       "      <td>16</td>\n",
       "      <td>308000</td>\n",
       "      <td>5.19</td>\n",
       "      <td>Albania1987</td>\n",
       "      <td>0.779</td>\n",
       "      <td>2,156,624,900</td>\n",
       "      <td>796</td>\n",
       "      <td>Silent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Albania</td>\n",
       "      <td>1987</td>\n",
       "      <td>female</td>\n",
       "      <td>15-24 years</td>\n",
       "      <td>14</td>\n",
       "      <td>289700</td>\n",
       "      <td>4.83</td>\n",
       "      <td>Albania1987</td>\n",
       "      <td>0.779</td>\n",
       "      <td>2,156,624,900</td>\n",
       "      <td>796</td>\n",
       "      <td>Generation X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Albania</td>\n",
       "      <td>1987</td>\n",
       "      <td>male</td>\n",
       "      <td>75+ years</td>\n",
       "      <td>1</td>\n",
       "      <td>21800</td>\n",
       "      <td>4.59</td>\n",
       "      <td>Albania1987</td>\n",
       "      <td>0.779</td>\n",
       "      <td>2,156,624,900</td>\n",
       "      <td>796</td>\n",
       "      <td>G.I. Generation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Albania</td>\n",
       "      <td>1987</td>\n",
       "      <td>male</td>\n",
       "      <td>25-34 years</td>\n",
       "      <td>9</td>\n",
       "      <td>274300</td>\n",
       "      <td>3.28</td>\n",
       "      <td>Albania1987</td>\n",
       "      <td>0.779</td>\n",
       "      <td>2,156,624,900</td>\n",
       "      <td>796</td>\n",
       "      <td>Boomers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ï»¿country  year     sex          age  suicides_no  population  \\\n",
       "0    Albania  1987    male  15-24 years           21      312900   \n",
       "1    Albania  1987    male  35-54 years           16      308000   \n",
       "2    Albania  1987  female  15-24 years           14      289700   \n",
       "3    Albania  1987    male    75+ years            1       21800   \n",
       "4    Albania  1987    male  25-34 years            9      274300   \n",
       "\n",
       "   suicides/100k pop country-year  HDI for year  gdp_for_year ($)   \\\n",
       "0               6.71  Albania1987         0.779      2,156,624,900   \n",
       "1               5.19  Albania1987         0.779      2,156,624,900   \n",
       "2               4.83  Albania1987         0.779      2,156,624,900   \n",
       "3               4.59  Albania1987         0.779      2,156,624,900   \n",
       "4               3.28  Albania1987         0.779      2,156,624,900   \n",
       "\n",
       "   gdp_per_capita ($)       generation  \n",
       "0                 796     Generation X  \n",
       "1                 796           Silent  \n",
       "2                 796     Generation X  \n",
       "3                 796  G.I. Generation  \n",
       "4                 796          Boomers  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median=df[\"HDI for year\"].median()\n",
    "print(\"median of column HDI for year\",median)\n",
    "df[\"HDI for year\"].fillna(median,inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le_file=LabelEncoder()\n",
    "input=df.drop('country-year',axis='columns')\n",
    "input['n_age']= le_file.fit_transform(df['age'])\n",
    "input['n_sex']= le_file.fit_transform(df['sex'])\n",
    "input['n_year']= le_file.fit_transform(df['year'])\n",
    "input['n_country']= le_file.fit_transform(df['ï»¿country'])\n",
    "output=input['n_sex']\n",
    "n_input=input.drop(['generation','population',' gdp_for_year ($) ','sex','ï»¿country','age','n_sex','suicides/100k pop','year'],axis='columns')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(n_input,output,test_size=0.3)\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>suicides_no</th>\n",
       "      <th>HDI for year</th>\n",
       "      <th>gdp_per_capita ($)</th>\n",
       "      <th>n_age</th>\n",
       "      <th>n_year</th>\n",
       "      <th>n_country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4069</th>\n",
       "      <td>1</td>\n",
       "      <td>0.779</td>\n",
       "      <td>4841</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14335</th>\n",
       "      <td>0</td>\n",
       "      <td>0.779</td>\n",
       "      <td>17668</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7786</th>\n",
       "      <td>20</td>\n",
       "      <td>0.779</td>\n",
       "      <td>1955</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2207</th>\n",
       "      <td>22</td>\n",
       "      <td>0.779</td>\n",
       "      <td>617</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24392</th>\n",
       "      <td>137</td>\n",
       "      <td>0.779</td>\n",
       "      <td>26978</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       suicides_no  HDI for year  gdp_per_capita ($)  n_age  n_year  n_country\n",
       "4069             1         0.779                4841      1      24         13\n",
       "14335            0         0.779               17668      5      17         49\n",
       "7786            20         0.779                1955      2       7         28\n",
       "2207            22         0.779                 617      0       8          7\n",
       "24392          137         0.779               26978      5       4         89"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4069     0\n",
       "14335    1\n",
       "7786     0\n",
       "2207     1\n",
       "24392    1\n",
       "Name: n_sex, dtype: int32"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UNTIL NOW WE HAVE DROPED SOME PARAMETERS AND HAVE SPLIT OUT DATASET INTO TRAINING DATASET AND TESTING DATASET IN THE RATIO OF 70:30."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K NEAREST NEIGHBOUR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the k-nearest neighbors algorithm (k-NN) is a non-parametric method used for classification and regression.In both cases, the input consists of the k closest training examples in the feature space. The output depends on whether k-NN is used for classification or regression:\n",
    "\n",
    "In k-NN classification, the output is a class membership. An object is classified by a plurality vote of its neighbors, with the object being assigned to the class most common among its k nearest neighbors (k is a positive integer, typically small). \n",
    "\n",
    "If k = 1, then the object is simply assigned to the class of that single nearest neighbor.\n",
    "\n",
    "In k-NN regression, the output is the property value for the object. This value is the average of the values of k nearest neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2506 1666]\n",
      " [2210 1964]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.60      0.56      4172\n",
      "           1       0.54      0.47      0.50      4174\n",
      "\n",
      "   micro avg       0.54      0.54      0.54      8346\n",
      "   macro avg       0.54      0.54      0.53      8346\n",
      "weighted avg       0.54      0.54      0.53      8346\n",
      "\n",
      "accuracy is 0.5355859094176851\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "clf=KNeighborsClassifier(n_neighbors=5) \n",
    "clf.fit(x_train, y_train)  \n",
    "y_pred = clf.predict(x_test)\n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"accuracy is\",clf.score(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RANDOM FOREST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest is a supervised learning algorithm. Like you can already see from it’s name, it creates a forest and makes it somehow random. The „forest“ it builds, is an ensemble of Decision Trees, most of the time trained with the “bagging” method. The general idea of the bagging method is that a combination of learning models increases the overall result. One big advantage of random forest is, that it can be used for both classification and regression problems.\n",
    "\n",
    "Random Forest has nearly the same hyperparameters as a decision tree or a bagging classifier. Random Forest adds additional randomness to the model, while growing the trees. Instead of searching for the most important feature while splitting a node, it searches for the best feature among a random subset of features. This results in a wide diversity that generally results in a better model.\n",
    "\n",
    "Therefore, in Random Forest, only a random subset of the features is taken into consideration by the algorithm for splitting a node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3144 1028]\n",
      " [1162 3012]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.75      0.74      4172\n",
      "           1       0.75      0.72      0.73      4174\n",
      "\n",
      "   micro avg       0.74      0.74      0.74      8346\n",
      "   macro avg       0.74      0.74      0.74      8346\n",
      "weighted avg       0.74      0.74      0.74      8346\n",
      "\n",
      "ACCURACY IS 0.7375988497483824\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=30)\n",
    "model.fit(x_train, y_train)\n",
    "mid=time.time()\n",
    "y_pred = model.predict(x_test)\n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"ACCURACY IS\",model.score(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DECISION TREE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A decision tree is a decision support tool that uses a tree-like graph or model of decisions and their possible consequences, including chance event outcomes, resource costs, and utility. It is one way to display an algorithm that only contains conditional control statements.\n",
    "\n",
    "A decision tree is a flowchart-like structure in which each internal node represents a “test” on an attribute (e.g. whether a coin flip comes up heads or tails), each branch represents the outcome of the test, and each leaf node represents a class label (decision taken after computing all attributes). The paths from root to leaf represent classification rules.\n",
    "\n",
    "Tree based learning algorithms are considered to be one of the best and mostly used supervised learning methods. Tree based methods empower predictive models with high accuracy, stability and ease of interpretation. Unlike linear models, they map non-linear relationships quite well. They are adaptable at solving any kind of problem at hand (classification or regression). Decision Tree algorithms are referred to as CART (Classification and Regression Trees)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3144 1028]\n",
      " [1162 3012]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.75      0.74      4172\n",
      "           1       0.75      0.72      0.73      4174\n",
      "\n",
      "   micro avg       0.74      0.74      0.74      8346\n",
      "   macro avg       0.74      0.74      0.74      8346\n",
      "weighted avg       0.74      0.74      0.74      8346\n",
      "\n",
      "ACCURACY IS 0.7510184519530314\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "model=tree.DecisionTreeClassifier()\n",
    "model.fit(x_train,y_train)\n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"ACCURACY IS\",model.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression is a Machine Learning classification algorithm that is used to predict the probability of a categorical dependent variable. In logistic regression, the dependent variable is a binary variable that contains data coded as 1 (yes, success, etc.) or 0 (no, failure, etc.). In other words, the logistic regression model predicts P(Y=1) as a function of X.\n",
    "\n",
    "Logistic Regression is one of the most popular ways to fit models for categorical data, especially for binary response data in Data Modeling. It is the most important (and probably most used) member of a class of models called generalized linear models. Unlike linear regression, logistic regression can directly predict probabilities (values that are restricted to the (0,1) interval); furthermore, those probabilities are well-calibrated when compared to the probabilities predicted by some other classifiers, such as Naive Bayes. Logistic regression preserves the marginal probabilities of the training data. The coefficients of the model also provide some hint of the relative importance of each input variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3144 1028]\n",
      " [1162 3012]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.75      0.74      4172\n",
      "           1       0.75      0.72      0.73      4174\n",
      "\n",
      "   micro avg       0.74      0.74      0.74      8346\n",
      "   macro avg       0.74      0.74      0.74      8346\n",
      "weighted avg       0.74      0.74      0.74      8346\n",
      "\n",
      "ACCURACY IS 0.5795590702132758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cloud\\Anaconda2\\envs\\gunjan\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(x_train, y_train)\n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"ACCURACY IS\",model.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machine are perhaps one of the most popular and talked about machine learning algorithms.They were extremely popular around the time they were developed in the 1990s and continue to be the go-to method for a high performing algorithm with little tuning. In this blog we will be mapping the various concepts of SVC. Support vector machines so called as SVM is a supervised learning algorithm which can be used for classification and regression problems as support vector classification (SVC) and support vector regression (SVR). It is used for smaller dataset as it takes too long to process.SVM is based on the idea of finding a hyperplane that best separates the features into different domains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cloud\\Anaconda2\\envs\\gunjan\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 954 3218]\n",
      " [1080 3094]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.23      0.31      4172\n",
      "           1       0.49      0.74      0.59      4174\n",
      "\n",
      "   micro avg       0.49      0.49      0.49      8346\n",
      "   macro avg       0.48      0.48      0.45      8346\n",
      "weighted avg       0.48      0.49      0.45      8346\n",
      "\n",
      "accuracy is 0.48502276539659717\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "model = SVC()\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"accuracy is\",model.score(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEATURE SELECTION WITH MACHINE LEARNING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRINCIPAL COMPONENT ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the common problems in analysis of complex data comes from a large number of variables, which requires a large amount of memory and computation power. This is where Principal Component Analysis (PCA) comes in. It is a technique to reduce the dimension of the feature space by feature extraction. For example, if we have 10 variables, in feature extraction, we create new independent variables by combining the old ten variables. By creating new variables it might seem as if more dimensions are introduced, but we select only a few variables from the newly created variables in the order of importance. Then the number of those selected variables is less than what we started with and that’s how we reduce the dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "# Make an instance of the Model\n",
    "pca = PCA(.70)\n",
    "pca.fit(x_train)\n",
    "x_train= pca.transform(x_train)\n",
    "x_test= pca.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2655 1517]\n",
      " [2459 1715]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.64      0.57      4172\n",
      "           1       0.53      0.41      0.46      4174\n",
      "\n",
      "   micro avg       0.52      0.52      0.52      8346\n",
      "   macro avg       0.52      0.52      0.52      8346\n",
      "weighted avg       0.52      0.52      0.52      8346\n",
      "\n",
      "accuracy is 0.5236041217349628\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "clf=KNeighborsClassifier(n_neighbors=3) \n",
    "clf.fit(x_train, y_train)  \n",
    "y_pred = clf.predict(x_test)\n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"accuracy is\",clf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2364 1808]\n",
      " [2167 2007]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.57      0.54      4172\n",
      "           1       0.53      0.48      0.50      4174\n",
      "\n",
      "   micro avg       0.52      0.52      0.52      8346\n",
      "   macro avg       0.52      0.52      0.52      8346\n",
      "weighted avg       0.52      0.52      0.52      8346\n",
      "\n",
      "ACCURACY IS 0.5237239396117901\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=30)\n",
    "model.fit(x_train, y_train)\n",
    "mid=time.time()\n",
    "y_pred = model.predict(x_test)\n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"ACCURACY IS\",model.score(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2364 1808]\n",
      " [2167 2007]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.57      0.54      4172\n",
      "           1       0.53      0.48      0.50      4174\n",
      "\n",
      "   micro avg       0.52      0.52      0.52      8346\n",
      "   macro avg       0.52      0.52      0.52      8346\n",
      "weighted avg       0.52      0.52      0.52      8346\n",
      "\n",
      "ACCURACY IS 0.531751737359214\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "model=tree.DecisionTreeClassifier()\n",
    "model.fit(x_train,y_train)\n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"ACCURACY IS\",model.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2364 1808]\n",
      " [2167 2007]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.57      0.54      4172\n",
      "           1       0.53      0.48      0.50      4174\n",
      "\n",
      "   micro avg       0.52      0.52      0.52      8346\n",
      "   macro avg       0.52      0.52      0.52      8346\n",
      "weighted avg       0.52      0.52      0.52      8346\n",
      "\n",
      "ACCURACY IS 0.49496764917325664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cloud\\Anaconda2\\envs\\gunjan\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(x_train, y_train)\n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"ACCURACY IS\",model.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "model = SVC()\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"accuracy is\",model.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutual Information "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In probability theory and information theory, the mutual information (MI) of two random variables is a measure of the mutual dependence between the two variables. More specifically, it quantifies the \"amount of information\" (in units such as shannons, commonly called bits) obtained about one random variable through observing the other random variable. The concept of mutual information is intricately linked to that of entropy of a random variable, a fundamental notion in information theory that quantifies the expected \"amount of information\" held in a random variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(n_input,output,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>suicides_no</th>\n",
       "      <th>HDI for year</th>\n",
       "      <th>gdp_per_capita ($)</th>\n",
       "      <th>n_age</th>\n",
       "      <th>n_year</th>\n",
       "      <th>n_country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5784</th>\n",
       "      <td>234</td>\n",
       "      <td>0.779</td>\n",
       "      <td>3106</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27416</th>\n",
       "      <td>48</td>\n",
       "      <td>0.779</td>\n",
       "      <td>3929</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26779</th>\n",
       "      <td>696</td>\n",
       "      <td>0.906</td>\n",
       "      <td>41798</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0</td>\n",
       "      <td>0.779</td>\n",
       "      <td>251</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17011</th>\n",
       "      <td>16</td>\n",
       "      <td>0.750</td>\n",
       "      <td>3870</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       suicides_no  HDI for year  gdp_per_capita ($)  n_age  n_year  n_country\n",
       "5784           234         0.779                3106      2      12         20\n",
       "27416           48         0.779                3929      0      18         99\n",
       "26779          696         0.906               41798      4      25         97\n",
       "45               0         0.779                 251      5       7          0\n",
       "17011           16         0.750                3870      4      20         60"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.feature_selection\n",
    "sklearn.feature_selection.mutual_info_classif(x_train,y_train, discrete_features='auto', n_neighbors=2, copy=True, random_state=None)\n",
    "x_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "decision tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3131  999]\n",
      " [1161 3055]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.76      0.74      4130\n",
      "           1       0.75      0.72      0.74      4216\n",
      "\n",
      "   micro avg       0.74      0.74      0.74      8346\n",
      "   macro avg       0.74      0.74      0.74      8346\n",
      "weighted avg       0.74      0.74      0.74      8346\n",
      "\n",
      "0.7411933860531992\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "model=tree.DecisionTreeClassifier()\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred))\n",
    "print(model.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3022 1108]\n",
      " [2714 1502]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.73      0.61      4130\n",
      "           1       0.58      0.36      0.44      4216\n",
      "\n",
      "   micro avg       0.54      0.54      0.54      8346\n",
      "   macro avg       0.55      0.54      0.53      8346\n",
      "weighted avg       0.55      0.54      0.53      8346\n",
      "\n",
      "accuracy is 0.5420560747663551\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "clf=KNeighborsClassifier(n_neighbors=10) \n",
    "clf.fit(x_train, y_train)  \n",
    "y_pred = clf.predict(x_test)\n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"accuracy is\",clf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3128 1002]\n",
      " [1254 2962]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.76      0.73      4130\n",
      "           1       0.75      0.70      0.72      4216\n",
      "\n",
      "   micro avg       0.73      0.73      0.73      8346\n",
      "   macro avg       0.73      0.73      0.73      8346\n",
      "weighted avg       0.73      0.73      0.73      8346\n",
      "\n",
      "ACCURACY IS 0.7296908698777858\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=30)\n",
    "model.fit(x_train, y_train)\n",
    "mid=time.time()\n",
    "y_pred = model.predict(x_test)\n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"ACCURACY IS\",model.score(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3022 1108]\n",
      " [2714 1502]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.73      0.61      4130\n",
      "           1       0.58      0.36      0.44      4216\n",
      "\n",
      "   micro avg       0.54      0.54      0.54      8346\n",
      "   macro avg       0.55      0.54      0.53      8346\n",
      "weighted avg       0.55      0.54      0.53      8346\n",
      "\n",
      "ACCURACY IS 0.5680565540378625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cloud\\Anaconda2\\envs\\gunjan\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(x_train, y_train)\n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"ACCURACY IS\",model.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cloud\\Anaconda2\\envs\\gunjan\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1012 3118]\n",
      " [1202 3014]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.25      0.32      4130\n",
      "           1       0.49      0.71      0.58      4216\n",
      "\n",
      "   micro avg       0.48      0.48      0.48      8346\n",
      "   macro avg       0.47      0.48      0.45      8346\n",
      "weighted avg       0.47      0.48      0.45      8346\n",
      "\n",
      "accuracy is 0.4823867721063983\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "model = SVC()\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"accuracy is\",model.score(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### boruta feautre selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Boruta algorithm is a wrapper built around the random forest classification algorithm. It tries to capture all the important, interesting features you might have in your dataset with respect to an outcome variable. Boruta is an all relevant feature selection wrapper algorithm, capable of working with any classification method that output variable importance measure (VIM); by default, Boruta uses Random Forest. The method performs a top-down search for relevant features by comparing original attributes' importance with importance achievable at random, estimated using their permuted copies, and progressively eliminating irrelevant features to stabilise that test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logisitic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t1 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t6\n",
      "Rejected: \t0\n",
      "Iteration: \t2 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t6\n",
      "Rejected: \t0\n",
      "Iteration: \t3 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t6\n",
      "Rejected: \t0\n",
      "Iteration: \t4 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t6\n",
      "Rejected: \t0\n",
      "Iteration: \t5 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t6\n",
      "Rejected: \t0\n",
      "Iteration: \t6 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t6\n",
      "Rejected: \t0\n",
      "Iteration: \t7 / 100\n",
      "Confirmed: \t2\n",
      "Tentative: \t1\n",
      "Rejected: \t3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cloud\\Anaconda2\\envs\\gunjan\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t8 / 100\n",
      "Confirmed: \t2\n",
      "Tentative: \t1\n",
      "Rejected: \t3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cloud\\Anaconda2\\envs\\gunjan\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t9 / 100\n",
      "Confirmed: \t2\n",
      "Tentative: \t1\n",
      "Rejected: \t3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cloud\\Anaconda2\\envs\\gunjan\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t10 / 100\n",
      "Confirmed: \t2\n",
      "Tentative: \t1\n",
      "Rejected: \t3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cloud\\Anaconda2\\envs\\gunjan\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t11 / 100\n",
      "Confirmed: \t2\n",
      "Tentative: \t1\n",
      "Rejected: \t3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cloud\\Anaconda2\\envs\\gunjan\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t12 / 100\n",
      "Confirmed: \t2\n",
      "Tentative: \t1\n",
      "Rejected: \t3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cloud\\Anaconda2\\envs\\gunjan\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t13 / 100\n",
      "Confirmed: \t2\n",
      "Tentative: \t1\n",
      "Rejected: \t3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cloud\\Anaconda2\\envs\\gunjan\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t14 / 100\n",
      "Confirmed: \t2\n",
      "Tentative: \t1\n",
      "Rejected: \t3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cloud\\Anaconda2\\envs\\gunjan\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t15 / 100\n",
      "Confirmed: \t2\n",
      "Tentative: \t1\n",
      "Rejected: \t3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cloud\\Anaconda2\\envs\\gunjan\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t16 / 100\n",
      "Confirmed: \t2\n",
      "Tentative: \t1\n",
      "Rejected: \t3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cloud\\Anaconda2\\envs\\gunjan\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t17 / 100\n",
      "Confirmed: \t2\n",
      "Tentative: \t1\n",
      "Rejected: \t3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cloud\\Anaconda2\\envs\\gunjan\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t18 / 100\n",
      "Confirmed: \t2\n",
      "Tentative: \t1\n",
      "Rejected: \t3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cloud\\Anaconda2\\envs\\gunjan\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t19 / 100\n",
      "Confirmed: \t2\n",
      "Tentative: \t1\n",
      "Rejected: \t3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cloud\\Anaconda2\\envs\\gunjan\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t20 / 100\n",
      "Confirmed: \t2\n",
      "Tentative: \t1\n",
      "Rejected: \t3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cloud\\Anaconda2\\envs\\gunjan\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t21 / 100\n",
      "Confirmed: \t2\n",
      "Tentative: \t1\n",
      "Rejected: \t3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cloud\\Anaconda2\\envs\\gunjan\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t22 / 100\n",
      "Confirmed: \t2\n",
      "Tentative: \t1\n",
      "Rejected: \t3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cloud\\Anaconda2\\envs\\gunjan\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t23 / 100\n",
      "Confirmed: \t2\n",
      "Tentative: \t1\n",
      "Rejected: \t3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cloud\\Anaconda2\\envs\\gunjan\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t24 / 100\n",
      "Confirmed: \t2\n",
      "Tentative: \t1\n",
      "Rejected: \t3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cloud\\Anaconda2\\envs\\gunjan\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t25 / 100\n",
      "Confirmed: \t2\n",
      "Tentative: \t1\n",
      "Rejected: \t3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cloud\\Anaconda2\\envs\\gunjan\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t26 / 100\n",
      "Confirmed: \t2\n",
      "Tentative: \t1\n",
      "Rejected: \t3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cloud\\Anaconda2\\envs\\gunjan\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t27 / 100\n",
      "Confirmed: \t2\n",
      "Tentative: \t1\n",
      "Rejected: \t3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cloud\\Anaconda2\\envs\\gunjan\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t28 / 100\n",
      "Confirmed: \t2\n",
      "Tentative: \t1\n",
      "Rejected: \t3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cloud\\Anaconda2\\envs\\gunjan\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t29 / 100\n",
      "Confirmed: \t2\n",
      "Tentative: \t1\n",
      "Rejected: \t3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cloud\\Anaconda2\\envs\\gunjan\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t30 / 100\n",
      "Confirmed: \t2\n",
      "Tentative: \t1\n",
      "Rejected: \t3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cloud\\Anaconda2\\envs\\gunjan\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t31 / 100\n",
      "Confirmed: \t2\n",
      "Tentative: \t1\n",
      "Rejected: \t3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cloud\\Anaconda2\\envs\\gunjan\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t32 / 100\n",
      "Confirmed: \t2\n",
      "Tentative: \t1\n",
      "Rejected: \t3\n",
      "Iteration: \t33 / 100\n",
      "Confirmed: \t3\n",
      "Tentative: \t0\n",
      "Rejected: \t3\n",
      "\n",
      "\n",
      "BorutaPy finished running.\n",
      "\n",
      "Iteration: \t34 / 100\n",
      "Confirmed: \t3\n",
      "Tentative: \t0\n",
      "Rejected: \t3\n",
      "[[3422  708]\n",
      " [2900 1316]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.83      0.65      4130\n",
      "           1       0.65      0.31      0.42      4216\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      8346\n",
      "   macro avg       0.60      0.57      0.54      8346\n",
      "weighted avg       0.60      0.57      0.54      8346\n",
      "\n",
      "accuracy is 0.5676971004073808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cloud\\Anaconda2\\envs\\gunjan\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n",
      "C:\\Users\\Cloud\\Anaconda2\\envs\\gunjan\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from boruta import BorutaPy\n",
    "rf = RandomForestClassifier(n_jobs=-1, class_weight='balanced')\n",
    "feat_selector = BorutaPy(rf, n_estimators='auto', verbose=2, random_state=1,alpha=0.09)\n",
    "feat_selector.fit(x_test.values,y_test.values)\n",
    "cols = x_train.columns[feat_selector.support_]\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "est_boruta = LogisticRegression()\n",
    "est_boruta.fit(x_train[cols], y_train)\n",
    "y_pred = est_boruta.predict(x_test[cols])\n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"accuracy is\",est_boruta.score(x_test[cols], y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3422  708]\n",
      " [2900 1316]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.83      0.65      4130\n",
      "           1       0.65      0.31      0.42      4216\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      8346\n",
      "   macro avg       0.60      0.57      0.54      8346\n",
      "weighted avg       0.60      0.57      0.54      8346\n",
      "\n",
      "ACCURACY IS 0.6574406901509705\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "model=tree.DecisionTreeClassifier()\n",
    "model.fit(x_train[cols],y_train)\n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"ACCURACY IS\",model.score(x_test[cols],y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3011 1119]\n",
      " [2674 1542]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.73      0.61      4130\n",
      "           1       0.58      0.37      0.45      4216\n",
      "\n",
      "   micro avg       0.55      0.55      0.55      8346\n",
      "   macro avg       0.55      0.55      0.53      8346\n",
      "weighted avg       0.55      0.55      0.53      8346\n",
      "\n",
      "accuracy is 0.5455307931943446\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "clf=KNeighborsClassifier(n_neighbors=10) \n",
    "clf.fit(x_train[cols], y_train)  \n",
    "y_pred = clf.predict(x_test[cols])\n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"accuracy is\",clf.score(x_test[cols], y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2897 1233]\n",
      " [1569 2647]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.70      0.67      4130\n",
      "           1       0.68      0.63      0.65      4216\n",
      "\n",
      "   micro avg       0.66      0.66      0.66      8346\n",
      "   macro avg       0.67      0.66      0.66      8346\n",
      "weighted avg       0.67      0.66      0.66      8346\n",
      "\n",
      "ACCURACY IS 0.6642703091301222\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=30)\n",
    "model.fit(x_train[cols], y_train)\n",
    "mid=time.time()\n",
    "y_pred = model.predict(x_test[cols])\n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"ACCURACY IS\",model.score(x_test[cols], y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cloud\\Anaconda2\\envs\\gunjan\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1010 3120]\n",
      " [1042 3174]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.24      0.33      4130\n",
      "           1       0.50      0.75      0.60      4216\n",
      "\n",
      "   micro avg       0.50      0.50      0.50      8346\n",
      "   macro avg       0.50      0.50      0.47      8346\n",
      "weighted avg       0.50      0.50      0.47      8346\n",
      "\n",
      "accuracy is 0.5013179966450995\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "model = SVC()\n",
    "model.fit(x_train[cols], y_train)\n",
    "y_pred = model.predict(x_test[cols])\n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"accuracy is\",model.score(x_test[cols], y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRAPHICAL ANALYSIS WITH MACHINE LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.tools as tls\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "x = [\"KNN\",\"RF\",\"DT\",\"LR\",\"SVM\"]\n",
    "N = len(y)\n",
    "y = [53.55,73.75,75.10,59.95,48.5]\n",
    "width = 1/1.5\n",
    "plt.bar(x, y, width, color=\"blue\")\n",
    "plt.title(\"WITHOUT FEATURE SELECTION\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [\"KNN\",\"RF\",\"DT\",\"LR\",\"SVM\"]\n",
    "N = len(y)\n",
    "y = [54.20,72.96,74.11,56.80,48.28]\n",
    "width = 1/1.5\n",
    "plt.bar(x, y, width, color=\"green\")\n",
    "plt.title(\"with mutual information\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [\"KNN\",\"RF\",\"DT\",\"LR\",\"SVM\"]\n",
    "N = len(y)\n",
    "y = [52.36,52.37,53.17,49.49,42.11]\n",
    "width = 1/1.5\n",
    "plt.bar(x, y, width, color=\"pink\")\n",
    "plt.title(\"with principal component analysis\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [\"KNN\",\"RF\",\"DT\",\"LR\",\"SVM\"]\n",
    "N = len(y)\n",
    "y = [54.55,66.42,65.74,56.76,50.13]\n",
    "width = 1/1.5\n",
    "plt.bar(x, y, width, color=\"red\")\n",
    "plt.title(\"with boruta\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
